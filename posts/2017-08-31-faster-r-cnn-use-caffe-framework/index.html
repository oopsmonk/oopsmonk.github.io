<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Faster R-CNN Use Caffe Framework | oopsmonk</title><meta name=keywords content="Linux,MachineLearning"><meta name=description content="Install caffe framework and run Faster R-CNN demo on Ubuntu 16.04.
Test environment
CPU: Intel(R) Core(TM) i3-4130 CPU @ 3.40GHz 4-Cores
GPU: ASUSTeK GeForce GTX 1060 with 6GB Memory
HD: WDC WD5000AAKX
OS: Ubuntu 16.04

Test Flow

Install software requirement
Video pre-processing: get jpeg images from source video
Image Labeling
Use Faster R-CNN to genrate trained model
Run Faster R-CNN demo

Requirement
Hardware:
Good graphic card with large memory (6GB memory is okay, but it has problem in VGG traing.)"><meta name=author content="oopsmonk"><link rel=canonical href=https://oopsmonk.github.io/posts/2017-08-31-faster-r-cnn-use-caffe-framework/><link crossorigin=anonymous href=/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://oopsmonk.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://oopsmonk.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://oopsmonk.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://oopsmonk.github.io/apple-touch-icon.png><link rel=mask-icon href=https://oopsmonk.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://oopsmonk.github.io/posts/2017-08-31-faster-r-cnn-use-caffe-framework/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=364511140"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","364511140")}</script><meta property="og:url" content="https://oopsmonk.github.io/posts/2017-08-31-faster-r-cnn-use-caffe-framework/"><meta property="og:site_name" content="oopsmonk"><meta property="og:title" content="Faster R-CNN Use Caffe Framework"><meta property="og:description" content="Install caffe framework and run Faster R-CNN demo on Ubuntu 16.04.
Test environment CPU: Intel(R) Core(TM) i3-4130 CPU @ 3.40GHz 4-Cores
GPU: ASUSTeK GeForce GTX 1060 with 6GB Memory
HD: WDC WD5000AAKX
OS: Ubuntu 16.04
Test Flow Install software requirement Video pre-processing: get jpeg images from source video Image Labeling Use Faster R-CNN to genrate trained model Run Faster R-CNN demo Requirement Hardware:
Good graphic card with large memory (6GB memory is okay, but it has problem in VGG traing.)"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2017-08-31T10:00:10+08:00"><meta property="article:modified_time" content="2017-08-31T10:00:10+08:00"><meta property="article:tag" content="Linux"><meta property="article:tag" content="MachineLearning"><meta property="og:image" content="https://oopsmonk.github.io/images/bio-oopsmonk.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://oopsmonk.github.io/images/bio-oopsmonk.jpg"><meta name=twitter:title content="Faster R-CNN Use Caffe Framework"><meta name=twitter:description content="Install caffe framework and run Faster R-CNN demo on Ubuntu 16.04.
Test environment
CPU: Intel(R) Core(TM) i3-4130 CPU @ 3.40GHz 4-Cores
GPU: ASUSTeK GeForce GTX 1060 with 6GB Memory
HD: WDC WD5000AAKX
OS: Ubuntu 16.04

Test Flow

Install software requirement
Video pre-processing: get jpeg images from source video
Image Labeling
Use Faster R-CNN to genrate trained model
Run Faster R-CNN demo

Requirement
Hardware:
Good graphic card with large memory (6GB memory is okay, but it has problem in VGG traing.)"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://oopsmonk.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Faster R-CNN Use Caffe Framework","item":"https://oopsmonk.github.io/posts/2017-08-31-faster-r-cnn-use-caffe-framework/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Faster R-CNN Use Caffe Framework","name":"Faster R-CNN Use Caffe Framework","description":"Install caffe framework and run Faster R-CNN demo on Ubuntu 16.04.\nTest environment CPU: Intel(R) Core(TM) i3-4130 CPU @ 3.40GHz 4-Cores\nGPU: ASUSTeK GeForce GTX 1060 with 6GB Memory\nHD: WDC WD5000AAKX\nOS: Ubuntu 16.04\nTest Flow Install software requirement Video pre-processing: get jpeg images from source video Image Labeling Use Faster R-CNN to genrate trained model Run Faster R-CNN demo Requirement Hardware:\nGood graphic card with large memory (6GB memory is okay, but it has problem in VGG traing.)\n","keywords":["Linux","MachineLearning"],"articleBody":"Install caffe framework and run Faster R-CNN demo on Ubuntu 16.04.\nTest environment CPU: Intel(R) Core(TM) i3-4130 CPU @ 3.40GHz 4-Cores\nGPU: ASUSTeK GeForce GTX 1060 with 6GB Memory\nHD: WDC WD5000AAKX\nOS: Ubuntu 16.04\nTest Flow Install software requirement Video pre-processing: get jpeg images from source video Image Labeling Use Faster R-CNN to genrate trained model Run Faster R-CNN demo Requirement Hardware:\nGood graphic card with large memory (6GB memory is okay, but it has problem in VGG traing.)\nSoftware:\nNvidia Driver CUDA 8.0 Python Packages OpenBLAS Caffe and pycaffe Install Software Requirements Update Nvidia Driver\nhttps://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa\nsudo add-apt-repository ppa:graphics-drivers/ppa sudo apt-get update sudo apt-get install nvidia-375 #You can use the latest one. # reboot system Install commands: Install.txt\nTraining data setup Generate image samples from video import cv2 print(cv2.__version__) vidcap = cv2.VideoCapture('video_file.mp4') success,image = vidcap.read() count = 0 success = True while success: success,image = vidcap.read() print 'Read a new frame: ', success cv2.imwrite(\"frame%d.jpg\" % count, image) # save frame as JPEG file count += 1 Image label tool https://github.com/tzutalin/labelImg\nTraining dataset setup Put all image files in\npy-faster-rcnn/data/VOCdevkit2007/VOC2007/JPEGImages\nPut all annotation files in\npy-faster-rcnn/data/VOCdevkit2007/VOC2007/Annotations\nGenerate test.txt, train.txt, trainval.txt, val.txt by these rules:\ntrainval.txt: ½ of the whole dataset\ntest.txt: ½ of the whole dataset\ntrain.txt: ½ of the trainval.txt val.txt: ½ of the trainval.txt\nIn my case:\nAnnotation files: 241 JPEJImage files: 362 test.txt: 116 samples train.txt: 62 samples trainval.txt: 125 samples val.txt: 62 samples py-faster-rcnn/data/VOCdevkit2007/VOC2007/ ├── Annotations │ └── *.xml ├── Annotations-back ├── ImageSets │ └── Main │ ├── test.txt │ ├── train.txt │ ├── trainval.txt │ └── val.txt └── JPEGImages └── *.jpg Part of test.txt\nframe1230 frame1240 frame1260 frame1370 frame1380 frame1390 frame1400 frame1410 frame1420 frame1430 ... 116 lines Part of train.txt\nframe1210 frame1250 frame1280 frame1300 frame1320 frame1340 frame1360 frame2040 ... 62 lines Part of trainval.txt\nframe1200 frame1210 frame1220 frame1250 frame1270 frame1280 frame1290 frame1300 frame1310 ... 125 lines Part of val.txt\nframe1200 frame1220 frame1270 frame1290 frame1310 frame1330 frame1350 frame2030 frame2050 ... 63 lines ZF model configure My clases number is 6, including the background class:\nModify num_classes to 6 Modify num_output in the cls_score layer to 6 Modify num_output in the bbox_pred layer to 4 * 6 diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/faster_rcnn_test.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/faster_rcnn_test.pt index b24aae4..fc1d677 100644 --- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/faster_rcnn_test.pt +++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/faster_rcnn_test.pt @@ -303,7 +303,7 @@ layer { bottom: \"fc7\" top: \"cls_score\" inner_product_param { - num_output: 21 + num_output: 6 } } layer { @@ -312,7 +312,7 @@ layer { bottom: \"fc7\" top: \"bbox_pred\" inner_product_param { - num_output: 84 + num_output: 24 } } layer { diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_train.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_train.pt index 3d98184..d7c7f26 100644 --- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_train.pt +++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_train.pt @@ -11,7 +11,7 @@ layer { python_param { module: 'roi_data_layer.layer' layer: 'RoIDataLayer' - param_str: \"'num_classes': 21\" + param_str: \"'num_classes': 6\" } } @@ -244,7 +244,7 @@ layer { param { lr_mult: 1.0 } param { lr_mult: 2.0 } inner_product_param { - num_output: 21 + num_output: 6 weight_filler { type: \"gaussian\" std: 0.01 @@ -263,7 +263,7 @@ layer { param { lr_mult: 1.0 } param { lr_mult: 2.0 } inner_product_param { - num_output: 84 + num_output: 24 weight_filler { type: \"gaussian\" std: 0.001 diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_train.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_train.pt index adf8605..c54e40d 100644 --- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_train.pt +++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_train.pt @@ -8,7 +8,7 @@ layer { python_param { module: 'roi_data_layer.layer' layer: 'RoIDataLayer' - param_str: \"'num_classes': 21\" + param_str: \"'num_classes': 6\" } } diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_train.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_train.pt index 262ed65..1a424a2 100644 --- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_train.pt +++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_train.pt @@ -11,7 +11,7 @@ layer { python_param { module: 'roi_data_layer.layer' layer: 'RoIDataLayer' - param_str: \"'num_classes': 21\" + param_str: \"'num_classes': 6\" } } @@ -244,7 +244,7 @@ layer { param { lr_mult: 1.0 } param { lr_mult: 2.0 } inner_product_param { - num_output: 21 + num_output: 6 weight_filler { type: \"gaussian\" std: 0.01 @@ -263,7 +263,7 @@ layer { param { lr_mult: 1.0 } param { lr_mult: 2.0 } inner_product_param { - num_output: 84 + num_output: 24 weight_filler { type: \"gaussian\" std: 0.001 diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_train.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_train.pt index 336b05b..bc0db0c 100644 --- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_train.pt +++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_train.pt @@ -8,7 +8,7 @@ layer { python_param { module: 'roi_data_layer.layer' layer: 'RoIDataLayer' - param_str: \"'num_classes': 21\" + param_str: \"'num_classes': 6\" } } Dataset Script My classes: kuaikuai, lays, soda, biscuit, noodle\ndiff --git a/lib/datasets/imdb.py b/lib/datasets/imdb.py index b56bf0a..93c85a4 100644 --- a/lib/datasets/imdb.py +++ b/lib/datasets/imdb.py @@ -108,6 +108,10 @@ class imdb(object): oldx2 = boxes[:, 2].copy() boxes[:, 0] = widths[i] - oldx2 - 1 boxes[:, 2] = widths[i] - oldx1 - 1 + for b in range(len(boxes)): + if boxes[b][2] \u003c boxes[b][0]: + boxes[b][0] = 0 + assert (boxes[:, 2] \u003e= boxes[:, 0]).all() entry = {'boxes' : boxes, 'gt_overlaps' : self.roidb[i]['gt_overlaps'], diff --git a/lib/datasets/pascal_voc.py b/lib/datasets/pascal_voc.py index b55f2f6..7a3473d 100644 --- a/lib/datasets/pascal_voc.py +++ b/lib/datasets/pascal_voc.py @@ -28,11 +28,12 @@ class pascal_voc(imdb): else devkit_path self._data_path = os.path.join(self._devkit_path, 'VOC' + self._year) self._classes = ('__background__', # always index 0 - 'aeroplane', 'bicycle', 'bird', 'boat', - 'bottle', 'bus', 'car', 'cat', 'chair', - 'cow', 'diningtable', 'dog', 'horse', - 'motorbike', 'person', 'pottedplant', - 'sheep', 'sofa', 'train', 'tvmonitor') + 'kuaikuai', 'lays', 'soda', 'biscuit', 'noodle') + # 'aeroplane', 'bicycle', 'bird', 'boat', + # 'bottle', 'bus', 'car', 'cat', 'chair', + # 'cow', 'diningtable', 'dog', 'horse', + # 'motorbike', 'person', 'pottedplant', + # 'sheep', 'sofa', 'train', 'tvmonitor') self._class_to_ind = dict(zip(self.classes, xrange(self.num_classes))) self._image_ext = '.jpg' self._image_index = self._load_image_set_index() update imdb.py and pascal_voc.py\ncd lib/datasets/ rm imdb.pyc pascal_voc.py # start python to compile pyc import py_compile py_compile.compile(r'imdb.py') py_compile.compile(r'pascal_voc.py') Speed up training for test only For make sure the training process works properly.\nModify train_faster_rcnn_alt_opt.py\ndiff --git a/tools/train_faster_rcnn_alt_opt.py b/tools/train_faster_rcnn_alt_opt.py index e49844a..1dafe3f 100755 --- a/tools/train_faster_rcnn_alt_opt.py +++ b/tools/train_faster_rcnn_alt_opt.py @@ -77,8 +77,9 @@ def get_solvers(net_name): [net_name, n, 'stage2_fast_rcnn_solver30k40k.pt']] solvers = [os.path.join(cfg.MODELS_DIR, *s) for s in solvers] # Iterations for each training stage - max_iters = [80000, 40000, 80000, 40000] - # max_iters = [100, 100, 100, 100] + # max_iters = [20000, 10000, 20000, 10000] + # max_iters = [80000, 40000, 80000, 40000] + max_iters = [100, 100, 100, 100] # Test prototxt for the RPN rpn_test_prototxt = os.path.join( cfg.MODELS_DIR, net_name, n, 'rpn_test.pt') Modify solvers\ndiff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_solver30k40k.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_solver30k40k.pt index 0180e7c..40636f0 100644 --- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_solver30k40k.pt +++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_solver30k40k.pt @@ -3,7 +3,7 @@ train_net: \"models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_train.pt\" base_lr: 0.001 lr_policy: \"step\" gamma: 0.1 -stepsize: 30000 +stepsize: 30 display: 20 average_loss: 100 momentum: 0.9 diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_solver60k80k.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_solver60k80k.pt index 23a7c6a..3f116dd 100644 --- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_solver60k80k.pt +++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_solver60k80k.pt @@ -3,7 +3,7 @@ train_net: \"models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_train.pt\" base_lr: 0.001 lr_policy: \"step\" gamma: 0.1 -stepsize: 60000 +stepsize: 50 display: 20 average_loss: 100 momentum: 0.9 diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_solver30k40k.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_solver30k40k.pt index a666def..2271d67 100644 --- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_solver30k40k.pt +++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_solver30k40k.pt @@ -3,7 +3,7 @@ train_net: \"models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_train.pt\" base_lr: 0.001 lr_policy: \"step\" gamma: 0.1 -stepsize: 30000 +stepsize: 30 display: 20 average_loss: 100 momentum: 0.9 diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_solver60k80k.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_solver60k80k.pt index 15d3da7..9d57101 100644 --- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_solver60k80k.pt +++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_solver60k80k.pt @@ -3,7 +3,7 @@ train_net: \"models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_train.pt\" base_lr: 0.001 lr_policy: \"step\" gamma: 0.1 -stepsize: 60000 +stepsize: 50 display: 20 average_loss: 100 momentum: 0.9 Outupt When you try to start a new round of training, you need to delete two cache files generated by last time.\nOne is /py-faster-rcnn/data/cache (delete the folder)\nThe other is /py-faster-rcnn/data/VOCdevkit2007/annotation_cache (if it exist, delete the folder)\n# if retain find . -name '*.pyc' | xargs rm # start training ./experiments/scripts/faster_rcnn_alt_opt.sh 0 ZF pascal_voc ... VOC07 metric? Yes Reading annotation for 1/116 Reading annotation for 101/116 Saving cached annotations to /home/dlsummer/RCNN-install/py-faster-rcnn/data/VOCdevkit2007/annotations_cache/annots.pkl AP for kuaikuai = 0.6687 AP for lays = 0.6286 AP for soda = 0.7081 AP for biscuit = 0.9091 AP for noodle = 0.4354 Mean AP = 0.6700 ~~~~~~~~ Results: 0.669 0.629 0.708 0.909 0.435 0.670 ~~~~~~~~ -------------------------------------------------------------- Results computed with the **unofficial** Python eval code. Results should be very close to the official MATLAB eval code. Recompute with `./tools/reval.py --matlab ...` for your paper. -- Thanks, The Management -------------------------------------------------------------- real 344m5.757s user 298m23.512s sys 45m38.792s Demo cp output/faster_rcnn_alt_opt/voc_2007_trainval/*.caffemodel ./data/faster_rcnn_models/ ## or cp output/faster_rcnn_alt_opt/voc_2007_trainval/zf_fast_rcnn_stage2_iter_100.caffemodel data/faster_rcnn_models/MY_ZF_faster_rcnn_final.caffemodel ## putting test images cp data/VOCdevkit2007/VOC2007/JPEGImages/???.jpg data/demo/ ## ex ## cp data/VOCdevkit2007/VOC2007/JPEGImages/G25_000?00.jpg data/demo/ ## run demo ./tools/demo_save_im.py --net zf Troubleshooting SSH: no display issue $ ./tool/demo.py Demo for data/demo/000456.jpg Detection took 0.198s for 300 object proposals Traceback (most recent call last): File \"./tools/demo.py\", line 149, in demo(net, im_name) File \"./tools/demo.py\", line 98, in demo vis_detections(im, cls, dets, thresh=CONF_THRESH) File \"./tools/demo.py\", line 47, in vis_detections fig, ax = plt.subplots(figsize=(12, 12)) File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 1202, in subplots fig = figure(**fig_kw) File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 535, in figure **kwargs) File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_tkagg.py\", line 81, in new_figure_manager return new_figure_manager_given_figure(num, figure) File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_tkagg.py\", line 89, in new_figure_manager_given_figure window = Tk.Tk() File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 1818, in __init__ self.tk = _tkinter.create(screenName, baseName, className, interactive, wantobjects, useTk, sync, use) _tkinter.TclError: no display name and no $DISPLAY environment variable Install Xming, Teamviewer or use X11 forwarding ssh -X\nhttp://blog.csdn.net/j790675692/article/details/52693761 Modify ./tool/demo.py diff --git a/tools/demo.py b/tools/demo.py index 631c68a..5016da5 100755 --- a/tools/demo.py +++ b/tools/demo.py @@ -13,6 +13,9 @@ Demo script showing detections in sample images. See README.md for installation instructions before running. \"\"\" +import matplotlib +matplotlib.use('Agg') + import _init_paths from fast_rcnn.config import cfg from fast_rcnn.test import im_detect @@ -67,7 +72,9 @@ def vis_detections(im, class_name, dets, thresh=0.5): fontsize=14) plt.axis('off') plt.tight_layout() - plt.draw() + #plt.draw() + pic_name = class_name + '_' + im_name + plt.savefig(pic_name) def demo(net, image_name): \"\"\"Detect object classes in an image using pre-computed object proposals.\"\"\" AttributeError: ‘module’ object has no attribute ’text_format’ $ ./experiments/scripts/faster_rcnn_alt_opt.sh 0 VGG16 pascal_voc [libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430 I0804 08:22:22.416573 2399 net.cpp:816] Ignoring source layer pool5 I0804 08:22:22.539361 2399 net.cpp:816] Ignoring source layer relu7 I0804 08:22:22.539386 2399 net.cpp:816] Ignoring source layer drop7 I0804 08:22:22.539389 2399 net.cpp:816] Ignoring source layer fc8 I0804 08:22:22.539392 2399 net.cpp:816] Ignoring source layer prob Process Process-1: Traceback (most recent call last): File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap self.run() File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run self._target(*self._args, **self._kwargs) File \"./tools/train_faster_rcnn_alt_opt.py\", line 129, in train_rpn max_iters=max_iters) File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/fast_rcnn/train.py\", line 157, in train_net pretrained_model=pretrained_model) File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/fast_rcnn/train.py\", line 51, in __init__ pb2.text_format.Merge(f.read(), self.solver_param) AttributeError: 'module' object has no attribute 'text_format' install protobuf==2.6.0\n$ sudo pip install protobuf==2.6.0 Ref: http://blog.csdn.net/qq_32768743/article/details/74639381\nOut of Memory I0804 08:28:56.610743 2742 net.cpp:270] This network produces output rpn_loss_bbox I0804 08:28:56.610782 2742 net.cpp:283] Network initialization done. I0804 08:28:56.610920 2742 solver.cpp:60] Solver scaffolding done. Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel [libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message. If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons. To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h. [libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430 I0804 08:28:56.840101 2742 net.cpp:816] Ignoring source layer pool5 I0804 08:28:56.961663 2742 net.cpp:816] Ignoring source layer relu7 I0804 08:28:56.961685 2742 net.cpp:816] Ignoring source layer drop7 I0804 08:28:56.961688 2742 net.cpp:816] Ignoring source layer fc8 I0804 08:28:56.961689 2742 net.cpp:816] Ignoring source layer prob Solving... F0804 08:28:57.365995 2742 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0) out of memory *** Check failure stack trace: *** ^C dlsummer@dlsummer-BM1AF-BP1AF-BM6AF:~/RCNN-install/py-faster-rcnn$ free -m total used free shared buff/cache available Mem: 11887 237 10480 17 1168 11350 Swap: 12159 0 12159 The graphic car out of memory Tried to train ZF model. GTX1060 may not have enough memory for VGG16. (I’m not sure the GPU is 6G ver. or 3G ver.)\nIn ZF model, you should modify:\nstage1_rpn_train.pt line 11 stage1.fast_rcnn_train.pt line 14, line 247 (In layer “cls_score”), line 266 (In layer “bbox_pred”) stage2_rpn_train.pt line 11 stage2.fast_rcnn_train.pt line 14, line 247 (In layer “cls_score”), line 266 (In layer “bbox_pred”) faster_rcnn_test.pt line 306 (In layer “cls_score”), line 315 (In layer “bbox_pred”) TypeError: ’numpy.float64’ object cannot be interpreted as an index Process Process-3: Traceback (most recent call last): File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap self.run() File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run self._target(*self._args, **self._kwargs) File \"./tools/train_faster_rcnn_alt_opt.py\", line 196, in train_fast_rcnn max_iters=max_iters) File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/fast_rcnn/train.py\", line 160, in train_net model_paths = sw.train_model(max_iters) File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/fast_rcnn/train.py\", line 101, in train_model self.solver.step(1) File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/layer.py\", line 144, in forward blobs = self._get_next_minibatch() File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/layer.py\", line 63, in _get_next_minibatch return get_minibatch(minibatch_db, self._num_classes) File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/minibatch.py\", line 55, in get_minibatch num_classes) File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/minibatch.py\", line 100, in _sample_rois fg_inds, size=fg_rois_per_this_image, replace=False) File \"mtrand.pyx\", line 1187, in mtrand.RandomState.choice (numpy/random/mtrand/mtrand.c:18864) TypeError: 'numpy.float64' object cannot be interpreted as an index Solution:\nhttps://github.com/rbgirshick/py-faster-rcnn/issues/481\nThere seems to be a similar error caused by line 173 in lib/roi_data_layer/minibatch.py.\ncls = clss[ind]\nThis is then used to slice bbox_targets[], however it is not an int and throws an error after hours of training. Change it to,\ncls = int(clss[ind])\nYou will save yourself a headache.\nvi lib/roi_data_layer/minibatch.py\nline 173: cls = int(clss[ind])\ndiff --git a/lib/roi_data_layer/minibatch.py b/lib/roi_data_layer/minibatch.py index f4535b0..dc15c62 100644 --- a/lib/roi_data_layer/minibatch.py +++ b/lib/roi_data_layer/minibatch.py @@ -93,7 +93,7 @@ def _sample_rois(roidb, fg_rois_per_image, rois_per_image, num_classes): fg_inds = np.where(overlaps \u003e= cfg.TRAIN.FG_THRESH)[0] # Guard against the case when an image has fewer than fg_rois_per_image # foreground RoIs - fg_rois_per_this_image = np.minimum(fg_rois_per_image, fg_inds.size) + fg_rois_per_this_image = int(np.minimum(fg_rois_per_image, fg_inds.size)) # Sample foreground regions without replacement if fg_inds.size \u003e 0: fg_inds = npr.choice( @@ -105,8 +105,8 @@ def _sample_rois(roidb, fg_rois_per_image, rois_per_image, num_classes): # Compute number of background RoIs to take from this image (guarding # against there being fewer than desired) bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image - bg_rois_per_this_image = np.minimum(bg_rois_per_this_image, - bg_inds.size) + bg_rois_per_this_image = int(np.minimum(bg_rois_per_this_image, + bg_inds.size)) # Sample foreground regions without replacement if bg_inds.size \u003e 0: bg_inds = npr.choice( @@ -170,7 +170,7 @@ def _get_bbox_regression_labels(bbox_target_data, num_classes): bbox_inside_weights = np.zeros(bbox_targets.shape, dtype=np.float32) inds = np.where(clss \u003e 0)[0] for ind in inds: - cls = clss[ind] + cls = int(clss[ind]) start = 4 * cls end = start + 4 bbox_targets[ind, start:end] = bbox_target_data[ind, 1:] ImportError: numpy.core.multiarray failed to import Traceback (most recent call last): File \"./tools/train_faster_rcnn_alt_opt.py\", line 19, in from datasets.factory import get_imdb File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/datasets/factory.py\", line 13, in from datasets.coco import coco File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/datasets/coco.py\", line 20, in from pycocotools.coco import COCO File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/pycocotools/coco.py\", line 58, in import mask File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/pycocotools/mask.py\", line 3, in import pycocotools._mask as _mask File \"pycocotools/_mask.pyx\", line 20, in init pycocotools._mask File \"__init__.pxd\", line 989, in numpy.import_array ImportError: numpy.core.multiarray failed to import Solution:\nsudo -H pip install --upgrade numpy\nTypeError: only length-1 arrays can be converted to Python scalars Process Process-3: Traceback (most recent call last): File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap self.run() File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run self._target(*self._args, **self._kwargs) File \"./tools/train_faster_rcnn_alt_opt.py\", line 196, in train_fast_rcnn max_iters=max_iters) File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/fast_rcnn/train.py\", line 160, in train_net model_paths = sw.train_model(max_iters) File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/fast_rcnn/train.py\", line 101, in train_model self.solver.step(1) File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/layer.py\", line 144, in forward blobs = self._get_next_minibatch() File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/layer.py\", line 63, in _get_next_minibatch return get_minibatch(minibatch_db, self._num_classes) File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/minibatch.py\", line 55, in get_minibatch num_classes) File \"/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/minibatch.py\", line 100, in _sample_rois int(fg_inds), size=fg_rois_per_this_image, replace=False) TypeError: only length-1 arrays can be converted to Python scalars Solution\nvi lib/roi_data_layer/minibatch.py\nline 100: size=int(fg_rois_per_this_image)\n","wordCount":"2363","inLanguage":"en","image":"https://oopsmonk.github.io/images/bio-oopsmonk.jpg","datePublished":"2017-08-31T10:00:10+08:00","dateModified":"2017-08-31T10:00:10+08:00","author":{"@type":"Person","name":"oopsmonk"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://oopsmonk.github.io/posts/2017-08-31-faster-r-cnn-use-caffe-framework/"},"publisher":{"@type":"Organization","name":"oopsmonk","logo":{"@type":"ImageObject","url":"https://oopsmonk.github.io/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://oopsmonk.github.io/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://oopsmonk.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://oopsmonk.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://oopsmonk.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://oopsmonk.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://oopsmonk.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://oopsmonk.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Faster R-CNN Use Caffe Framework</h1><div class=post-meta><span title='2017-08-31 10:00:10 +0800 +0800'>August 31, 2017</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;oopsmonk&nbsp;|&nbsp;<a href=https://github.com/oopsmonk/oopsmonk.github.io/issues rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>Install caffe framework and run Faster R-CNN demo on Ubuntu 16.04.</p><h3 id=test-environment>Test environment<a hidden class=anchor aria-hidden=true href=#test-environment>#</a></h3><p>CPU: Intel(R) Core(TM) i3-4130 CPU @ 3.40GHz 4-Cores<br>GPU: ASUSTeK GeForce GTX 1060 with 6GB Memory<br>HD: WDC WD5000AAKX<br>OS: Ubuntu 16.04</p><p><img loading=lazy src=/images/2017-08-31/GPU_Info.png></p><h3 id=test-flow>Test Flow<a hidden class=anchor aria-hidden=true href=#test-flow>#</a></h3><ul><li>Install software requirement</li><li>Video pre-processing: get jpeg images from source video</li><li>Image Labeling</li><li>Use Faster R-CNN to genrate trained model</li><li>Run Faster R-CNN demo</li></ul><h3 id=requirement>Requirement<a hidden class=anchor aria-hidden=true href=#requirement>#</a></h3><p>Hardware:<br>Good graphic card with large memory (6GB memory is okay, but it has problem in VGG traing.)</p><p>Software:</p><ul><li>Nvidia Driver</li><li>CUDA 8.0</li><li>Python Packages</li><li>OpenBLAS</li><li>Caffe and pycaffe</li></ul><h3 id=install-software-requirements>Install Software Requirements<a hidden class=anchor aria-hidden=true href=#install-software-requirements>#</a></h3><p><strong>Update Nvidia Driver</strong><br><a href=https://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa>https://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo add-apt-repository ppa:graphics-drivers/ppa
</span></span><span style=display:flex><span>sudo apt-get update
</span></span><span style=display:flex><span>sudo apt-get install nvidia-375   <span style=color:#75715e>#You can use the latest one.  </span>
</span></span><span style=display:flex><span><span style=color:#75715e># reboot system</span>
</span></span></code></pre></div><p>Install commands: <strong><a href=/resource/2017-08-31/FRCNN_InstallCommands.txt>Install.txt</a></strong></p><h2 id=training-data-setup>Training data setup<a hidden class=anchor aria-hidden=true href=#training-data-setup>#</a></h2><h3 id=generate-image-samples-from-video>Generate image samples from video<a hidden class=anchor aria-hidden=true href=#generate-image-samples-from-video>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> cv2
</span></span><span style=display:flex><span>print(cv2<span style=color:#f92672>.</span>__version__)
</span></span><span style=display:flex><span>vidcap <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>VideoCapture(<span style=color:#e6db74>&#39;video_file.mp4&#39;</span>)
</span></span><span style=display:flex><span>success,image <span style=color:#f92672>=</span> vidcap<span style=color:#f92672>.</span>read()
</span></span><span style=display:flex><span>count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>success <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>while</span> success:
</span></span><span style=display:flex><span>  success,image <span style=color:#f92672>=</span> vidcap<span style=color:#f92672>.</span>read()
</span></span><span style=display:flex><span>  print <span style=color:#e6db74>&#39;Read a new frame: &#39;</span>, success
</span></span><span style=display:flex><span>  cv2<span style=color:#f92672>.</span>imwrite(<span style=color:#e6db74>&#34;frame</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>.jpg&#34;</span> <span style=color:#f92672>%</span> count, image)     <span style=color:#75715e># save frame as JPEG file</span>
</span></span><span style=display:flex><span>  count <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span></code></pre></div><h3 id=image-label-tool>Image label tool<a hidden class=anchor aria-hidden=true href=#image-label-tool>#</a></h3><p><a href=https://github.com/tzutalin/labelImg>https://github.com/tzutalin/labelImg</a></p><h3 id=training-dataset-setup>Training dataset setup<a hidden class=anchor aria-hidden=true href=#training-dataset-setup>#</a></h3><ul><li><p>Put all image files in<br>py-faster-rcnn/data/VOCdevkit2007/VOC2007/JPEGImages</p></li><li><p>Put all annotation files in<br>py-faster-rcnn/data/VOCdevkit2007/VOC2007/Annotations</p></li><li><p>Generate test.txt, train.txt, trainval.txt, val.txt by these rules:<br>trainval.txt: ½ of the whole dataset<br>test.txt: ½ of the whole dataset<br>train.txt: ½ of the trainval.txt
val.txt: ½ of the trainval.txt</p></li></ul><p>In my case:</p><ul><li>Annotation files: 241</li><li>JPEJImage files: 362</li><li>test.txt: 116 samples</li><li>train.txt: 62 samples</li><li>trainval.txt: 125 samples</li><li>val.txt: 62 samples</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>py-faster-rcnn/data/VOCdevkit2007/VOC2007/
</span></span><span style=display:flex><span>├── Annotations
</span></span><span style=display:flex><span>│     └── *.xml
</span></span><span style=display:flex><span>├── Annotations-back
</span></span><span style=display:flex><span>├── ImageSets
</span></span><span style=display:flex><span>│     └── Main
</span></span><span style=display:flex><span>│       ├── test.txt
</span></span><span style=display:flex><span>│       ├── train.txt
</span></span><span style=display:flex><span>│       ├── trainval.txt
</span></span><span style=display:flex><span>│       └── val.txt
</span></span><span style=display:flex><span>└── JPEGImages
</span></span><span style=display:flex><span>      └── *.jpg
</span></span></code></pre></div><p>Part of test.txt</p><pre tabindex=0><code>frame1230
frame1240
frame1260
frame1370
frame1380
frame1390
frame1400
frame1410
frame1420
frame1430
...
116 lines
</code></pre><p>Part of train.txt</p><pre tabindex=0><code>frame1210
frame1250
frame1280
frame1300
frame1320
frame1340
frame1360
frame2040
...
62 lines
</code></pre><p>Part of trainval.txt</p><pre tabindex=0><code>frame1200
frame1210
frame1220
frame1250
frame1270
frame1280
frame1290
frame1300
frame1310
...
125 lines
</code></pre><p>Part of val.txt</p><pre tabindex=0><code>frame1200
frame1220
frame1270
frame1290
frame1310
frame1330
frame1350
frame2030
frame2050
...
63 lines
</code></pre><h3 id=zf-model-configure>ZF model configure<a hidden class=anchor aria-hidden=true href=#zf-model-configure>#</a></h3><p>My clases number is 6, including the background class:</p><ul><li>Modify <code>num_classes</code> to 6</li><li>Modify <code>num_output</code> in the <code>cls_score</code> layer to 6</li><li>Modify <code>num_output</code> in the <code>bbox_pred</code> layer to 4 * 6</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/faster_rcnn_test.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/faster_rcnn_test.pt
</span></span><span style=display:flex><span>index b24aae4..fc1d677 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/faster_rcnn_test.pt
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/faster_rcnn_test.pt
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -303,7 +303,7 @@ layer {
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>   bottom: &#34;fc7&#34;
</span></span><span style=display:flex><span>   top: &#34;cls_score&#34;
</span></span><span style=display:flex><span>   inner_product_param {
</span></span><span style=display:flex><span><span style=color:#f92672>-    num_output: 21
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    num_output: 6
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>   }
</span></span><span style=display:flex><span> }
</span></span><span style=display:flex><span> layer {
</span></span><span style=display:flex><span><span style=color:#75715e>@@ -312,7 +312,7 @@ layer {
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>   bottom: &#34;fc7&#34;
</span></span><span style=display:flex><span>   top: &#34;bbox_pred&#34;
</span></span><span style=display:flex><span>   inner_product_param {
</span></span><span style=display:flex><span><span style=color:#f92672>-    num_output: 84
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    num_output: 24
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>   }
</span></span><span style=display:flex><span> }
</span></span><span style=display:flex><span> layer {
</span></span><span style=display:flex><span>diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_train.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_train.pt
</span></span><span style=display:flex><span>index 3d98184..d7c7f26 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_train.pt
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_train.pt
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -11,7 +11,7 @@ layer {
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>   python_param {
</span></span><span style=display:flex><span>     module: &#39;roi_data_layer.layer&#39;
</span></span><span style=display:flex><span>     layer: &#39;RoIDataLayer&#39;
</span></span><span style=display:flex><span><span style=color:#f92672>-    param_str: &#34;&#39;num_classes&#39;: 21&#34;
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    param_str: &#34;&#39;num_classes&#39;: 6&#34;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>   }
</span></span><span style=display:flex><span> }
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span><span style=color:#75715e>@@ -244,7 +244,7 @@ layer {
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>   param { lr_mult: 1.0 }
</span></span><span style=display:flex><span>   param { lr_mult: 2.0 }
</span></span><span style=display:flex><span>   inner_product_param {
</span></span><span style=display:flex><span><span style=color:#f92672>-    num_output: 21
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    num_output: 6
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>     weight_filler {
</span></span><span style=display:flex><span>       type: &#34;gaussian&#34;
</span></span><span style=display:flex><span>       std: 0.01
</span></span><span style=display:flex><span><span style=color:#75715e>@@ -263,7 +263,7 @@ layer {
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>   param { lr_mult: 1.0 }
</span></span><span style=display:flex><span>   param { lr_mult: 2.0 }
</span></span><span style=display:flex><span>   inner_product_param {
</span></span><span style=display:flex><span><span style=color:#f92672>-    num_output: 84
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    num_output: 24
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>     weight_filler {
</span></span><span style=display:flex><span>       type: &#34;gaussian&#34;
</span></span><span style=display:flex><span>       std: 0.001
</span></span><span style=display:flex><span>diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_train.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_train.pt
</span></span><span style=display:flex><span>index adf8605..c54e40d 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_train.pt
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_train.pt
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -8,7 +8,7 @@ layer {
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>   python_param {
</span></span><span style=display:flex><span>     module: &#39;roi_data_layer.layer&#39;
</span></span><span style=display:flex><span>     layer: &#39;RoIDataLayer&#39;
</span></span><span style=display:flex><span><span style=color:#f92672>-    param_str: &#34;&#39;num_classes&#39;: 21&#34;
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    param_str: &#34;&#39;num_classes&#39;: 6&#34;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>   }
</span></span><span style=display:flex><span> }
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_train.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_train.pt
</span></span><span style=display:flex><span>index 262ed65..1a424a2 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_train.pt
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_train.pt
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -11,7 +11,7 @@ layer {
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>   python_param {
</span></span><span style=display:flex><span>     module: &#39;roi_data_layer.layer&#39;
</span></span><span style=display:flex><span>     layer: &#39;RoIDataLayer&#39;
</span></span><span style=display:flex><span><span style=color:#f92672>-    param_str: &#34;&#39;num_classes&#39;: 21&#34;
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    param_str: &#34;&#39;num_classes&#39;: 6&#34;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>   }
</span></span><span style=display:flex><span> }
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span><span style=color:#75715e>@@ -244,7 +244,7 @@ layer {
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>   param { lr_mult: 1.0 }
</span></span><span style=display:flex><span>   param { lr_mult: 2.0 }
</span></span><span style=display:flex><span>   inner_product_param {
</span></span><span style=display:flex><span><span style=color:#f92672>-    num_output: 21
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    num_output: 6
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>     weight_filler {
</span></span><span style=display:flex><span>       type: &#34;gaussian&#34;
</span></span><span style=display:flex><span>       std: 0.01
</span></span><span style=display:flex><span><span style=color:#75715e>@@ -263,7 +263,7 @@ layer {
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>   param { lr_mult: 1.0 }
</span></span><span style=display:flex><span>   param { lr_mult: 2.0 }
</span></span><span style=display:flex><span>   inner_product_param {
</span></span><span style=display:flex><span><span style=color:#f92672>-    num_output: 84
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    num_output: 24
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>     weight_filler {
</span></span><span style=display:flex><span>       type: &#34;gaussian&#34;
</span></span><span style=display:flex><span>       std: 0.001
</span></span><span style=display:flex><span>diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_train.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_train.pt
</span></span><span style=display:flex><span>index 336b05b..bc0db0c 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_train.pt
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_train.pt
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -8,7 +8,7 @@ layer {
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>   python_param {
</span></span><span style=display:flex><span>     module: &#39;roi_data_layer.layer&#39;
</span></span><span style=display:flex><span>     layer: &#39;RoIDataLayer&#39;
</span></span><span style=display:flex><span><span style=color:#f92672>-    param_str: &#34;&#39;num_classes&#39;: 21&#34;
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    param_str: &#34;&#39;num_classes&#39;: 6&#34;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>   }
</span></span><span style=display:flex><span> }
</span></span><span style=display:flex><span> 
</span></span></code></pre></div><h3 id=dataset-script>Dataset Script<a hidden class=anchor aria-hidden=true href=#dataset-script>#</a></h3><p>My classes: <strong>kuaikuai</strong>, <strong>lays</strong>, <strong>soda</strong>, <strong>biscuit</strong>, <strong>noodle</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>diff --git a/lib/datasets/imdb.py b/lib/datasets/imdb.py
</span></span><span style=display:flex><span>index b56bf0a..93c85a4 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/lib/datasets/imdb.py
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/lib/datasets/imdb.py
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -108,6 +108,10 @@ class imdb(object):
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>             oldx2 = boxes[:, 2].copy()
</span></span><span style=display:flex><span>             boxes[:, 0] = widths[i] - oldx2 - 1
</span></span><span style=display:flex><span>             boxes[:, 2] = widths[i] - oldx1 - 1
</span></span><span style=display:flex><span><span style=color:#a6e22e>+            for b in range(len(boxes)):
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+                if boxes[b][2] &lt; boxes[b][0]:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+                    boxes[b][0] = 0
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>             assert (boxes[:, 2] &gt;= boxes[:, 0]).all()
</span></span><span style=display:flex><span>             entry = {&#39;boxes&#39; : boxes,
</span></span><span style=display:flex><span>                      &#39;gt_overlaps&#39; : self.roidb[i][&#39;gt_overlaps&#39;],
</span></span><span style=display:flex><span>diff --git a/lib/datasets/pascal_voc.py b/lib/datasets/pascal_voc.py
</span></span><span style=display:flex><span>index b55f2f6..7a3473d 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/lib/datasets/pascal_voc.py
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/lib/datasets/pascal_voc.py
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -28,11 +28,12 @@ class pascal_voc(imdb):
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>                             else devkit_path
</span></span><span style=display:flex><span>         self._data_path = os.path.join(self._devkit_path, &#39;VOC&#39; + self._year)
</span></span><span style=display:flex><span>         self._classes = (&#39;__background__&#39;, # always index 0
</span></span><span style=display:flex><span><span style=color:#f92672>-                         &#39;aeroplane&#39;, &#39;bicycle&#39;, &#39;bird&#39;, &#39;boat&#39;,
</span></span></span><span style=display:flex><span><span style=color:#f92672>-                         &#39;bottle&#39;, &#39;bus&#39;, &#39;car&#39;, &#39;cat&#39;, &#39;chair&#39;,
</span></span></span><span style=display:flex><span><span style=color:#f92672>-                         &#39;cow&#39;, &#39;diningtable&#39;, &#39;dog&#39;, &#39;horse&#39;,
</span></span></span><span style=display:flex><span><span style=color:#f92672>-                         &#39;motorbike&#39;, &#39;person&#39;, &#39;pottedplant&#39;,
</span></span></span><span style=display:flex><span><span style=color:#f92672>-                         &#39;sheep&#39;, &#39;sofa&#39;, &#39;train&#39;, &#39;tvmonitor&#39;)
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+                         &#39;kuaikuai&#39;, &#39;lays&#39;, &#39;soda&#39;, &#39;biscuit&#39;, &#39;noodle&#39;)
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+                         # &#39;aeroplane&#39;, &#39;bicycle&#39;, &#39;bird&#39;, &#39;boat&#39;,
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+                         # &#39;bottle&#39;, &#39;bus&#39;, &#39;car&#39;, &#39;cat&#39;, &#39;chair&#39;,
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+                         # &#39;cow&#39;, &#39;diningtable&#39;, &#39;dog&#39;, &#39;horse&#39;,
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+                         # &#39;motorbike&#39;, &#39;person&#39;, &#39;pottedplant&#39;,
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+                         # &#39;sheep&#39;, &#39;sofa&#39;, &#39;train&#39;, &#39;tvmonitor&#39;)
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>         self._class_to_ind = dict(zip(self.classes, xrange(self.num_classes)))
</span></span><span style=display:flex><span>         self._image_ext = &#39;.jpg&#39;
</span></span><span style=display:flex><span>         self._image_index = self._load_image_set_index()
</span></span></code></pre></div><p><strong>update imdb.py and pascal_voc.py</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cd lib/datasets/
</span></span><span style=display:flex><span>rm imdb.pyc pascal_voc.py
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># start python to compile pyc</span>
</span></span><span style=display:flex><span>import py_compile
</span></span><span style=display:flex><span>py_compile.compile<span style=color:#f92672>(</span>r<span style=color:#e6db74>&#39;imdb.py&#39;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>py_compile.compile<span style=color:#f92672>(</span>r<span style=color:#e6db74>&#39;pascal_voc.py&#39;</span><span style=color:#f92672>)</span>
</span></span></code></pre></div><h3 id=speed-up-training-for-test-only>Speed up training for test only<a hidden class=anchor aria-hidden=true href=#speed-up-training-for-test-only>#</a></h3><p>For make sure the training process works properly.</p><p>Modify train_faster_rcnn_alt_opt.py</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>diff --git a/tools/train_faster_rcnn_alt_opt.py b/tools/train_faster_rcnn_alt_opt.py
</span></span><span style=display:flex><span>index e49844a..1dafe3f 100755
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/tools/train_faster_rcnn_alt_opt.py
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/tools/train_faster_rcnn_alt_opt.py
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -77,8 +77,9 @@ def get_solvers(net_name):
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>                [net_name, n, &#39;stage2_fast_rcnn_solver30k40k.pt&#39;]]
</span></span><span style=display:flex><span>     solvers = [os.path.join(cfg.MODELS_DIR, *s) for s in solvers]
</span></span><span style=display:flex><span>     # Iterations for each training stage
</span></span><span style=display:flex><span><span style=color:#f92672>-    max_iters = [80000, 40000, 80000, 40000]
</span></span></span><span style=display:flex><span><span style=color:#f92672>-    # max_iters = [100, 100, 100, 100]
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    # max_iters = [20000, 10000, 20000, 10000]
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    # max_iters = [80000, 40000, 80000, 40000]
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    max_iters = [100, 100, 100, 100]
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>     # Test prototxt for the RPN
</span></span><span style=display:flex><span>     rpn_test_prototxt = os.path.join(
</span></span><span style=display:flex><span>         cfg.MODELS_DIR, net_name, n, &#39;rpn_test.pt&#39;)
</span></span></code></pre></div><p>Modify solvers</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_solver30k40k.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_solver30k40k.pt
</span></span><span style=display:flex><span>index 0180e7c..40636f0 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_solver30k40k.pt
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_solver30k40k.pt
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -3,7 +3,7 @@ train_net: &#34;models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_fast_rcnn_train.pt&#34;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span> base_lr: 0.001
</span></span><span style=display:flex><span> lr_policy: &#34;step&#34;
</span></span><span style=display:flex><span> gamma: 0.1
</span></span><span style=display:flex><span><span style=color:#f92672>-stepsize: 30000
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+stepsize: 30
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span> display: 20
</span></span><span style=display:flex><span> average_loss: 100
</span></span><span style=display:flex><span> momentum: 0.9
</span></span><span style=display:flex><span>diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_solver60k80k.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_solver60k80k.pt
</span></span><span style=display:flex><span>index 23a7c6a..3f116dd 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_solver60k80k.pt
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_solver60k80k.pt
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -3,7 +3,7 @@ train_net: &#34;models/pascal_voc/ZF/faster_rcnn_alt_opt/stage1_rpn_train.pt&#34;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span> base_lr: 0.001
</span></span><span style=display:flex><span> lr_policy: &#34;step&#34;
</span></span><span style=display:flex><span> gamma: 0.1
</span></span><span style=display:flex><span><span style=color:#f92672>-stepsize: 60000
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+stepsize: 50
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span> display: 20
</span></span><span style=display:flex><span> average_loss: 100
</span></span><span style=display:flex><span> momentum: 0.9
</span></span><span style=display:flex><span>diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_solver30k40k.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_solver30k40k.pt
</span></span><span style=display:flex><span>index a666def..2271d67 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_solver30k40k.pt
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_solver30k40k.pt
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -3,7 +3,7 @@ train_net: &#34;models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_fast_rcnn_train.pt&#34;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span> base_lr: 0.001
</span></span><span style=display:flex><span> lr_policy: &#34;step&#34;
</span></span><span style=display:flex><span> gamma: 0.1
</span></span><span style=display:flex><span><span style=color:#f92672>-stepsize: 30000
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+stepsize: 30
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span> display: 20
</span></span><span style=display:flex><span> average_loss: 100
</span></span><span style=display:flex><span> momentum: 0.9
</span></span><span style=display:flex><span>diff --git a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_solver60k80k.pt b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_solver60k80k.pt
</span></span><span style=display:flex><span>index 15d3da7..9d57101 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_solver60k80k.pt
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_solver60k80k.pt
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -3,7 +3,7 @@ train_net: &#34;models/pascal_voc/ZF/faster_rcnn_alt_opt/stage2_rpn_train.pt&#34;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span> base_lr: 0.001
</span></span><span style=display:flex><span> lr_policy: &#34;step&#34;
</span></span><span style=display:flex><span> gamma: 0.1
</span></span><span style=display:flex><span><span style=color:#f92672>-stepsize: 60000
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+stepsize: 50
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span> display: 20
</span></span><span style=display:flex><span> average_loss: 100
</span></span><span style=display:flex><span> momentum: 0.9
</span></span></code></pre></div><h2 id=outupt>Outupt<a hidden class=anchor aria-hidden=true href=#outupt>#</a></h2><p>When you try to start a new round of training, you need to delete two cache files generated by last time.<br>One is <strong>/py-faster-rcnn/data/cache (delete the folder)</strong><br>The other is <strong>/py-faster-rcnn/data/VOCdevkit2007/annotation_cache (if it exist, delete the folder)</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#75715e># if retain </span>
</span></span><span style=display:flex><span>find . -name <span style=color:#e6db74>&#39;*.pyc&#39;</span> | xargs rm
</span></span><span style=display:flex><span><span style=color:#75715e># start training</span>
</span></span><span style=display:flex><span>./experiments/scripts/faster_rcnn_alt_opt.sh <span style=color:#ae81ff>0</span> ZF pascal_voc
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>VOC07 metric? Yes
</span></span><span style=display:flex><span>Reading annotation <span style=color:#66d9ef>for</span> 1/116
</span></span><span style=display:flex><span>Reading annotation <span style=color:#66d9ef>for</span> 101/116
</span></span><span style=display:flex><span>Saving cached annotations to /home/dlsummer/RCNN-install/py-faster-rcnn/data/VOCdevkit2007/annotations_cache/annots.pkl
</span></span><span style=display:flex><span>AP <span style=color:#66d9ef>for</span> kuaikuai <span style=color:#f92672>=</span> 0.6687
</span></span><span style=display:flex><span>AP <span style=color:#66d9ef>for</span> lays <span style=color:#f92672>=</span> 0.6286
</span></span><span style=display:flex><span>AP <span style=color:#66d9ef>for</span> soda <span style=color:#f92672>=</span> 0.7081
</span></span><span style=display:flex><span>AP <span style=color:#66d9ef>for</span> biscuit <span style=color:#f92672>=</span> 0.9091
</span></span><span style=display:flex><span>AP <span style=color:#66d9ef>for</span> noodle <span style=color:#f92672>=</span> 0.4354
</span></span><span style=display:flex><span>Mean AP <span style=color:#f92672>=</span> 0.6700
</span></span><span style=display:flex><span>~~~~~~~~
</span></span><span style=display:flex><span>Results:
</span></span><span style=display:flex><span>0.669
</span></span><span style=display:flex><span>0.629
</span></span><span style=display:flex><span>0.708
</span></span><span style=display:flex><span>0.909
</span></span><span style=display:flex><span>0.435
</span></span><span style=display:flex><span>0.670
</span></span><span style=display:flex><span>~~~~~~~~
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>--------------------------------------------------------------
</span></span><span style=display:flex><span>Results computed with the **unofficial** Python eval code.
</span></span><span style=display:flex><span>Results should be very close to the official MATLAB eval code.
</span></span><span style=display:flex><span>Recompute with <span style=color:#e6db74>`</span>./tools/reval.py --matlab ...<span style=color:#e6db74>`</span> <span style=color:#66d9ef>for</span> your paper.
</span></span><span style=display:flex><span>-- Thanks, The Management
</span></span><span style=display:flex><span>--------------------------------------------------------------
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>real    344m5.757s
</span></span><span style=display:flex><span>user    298m23.512s
</span></span><span style=display:flex><span>sys     45m38.792s
</span></span></code></pre></div><h3 id=demo>Demo<a hidden class=anchor aria-hidden=true href=#demo>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cp output/faster_rcnn_alt_opt/voc_2007_trainval/*.caffemodel ./data/faster_rcnn_models/
</span></span><span style=display:flex><span><span style=color:#75715e>## or </span>
</span></span><span style=display:flex><span>cp output/faster_rcnn_alt_opt/voc_2007_trainval/zf_fast_rcnn_stage2_iter_100.caffemodel data/faster_rcnn_models/MY_ZF_faster_rcnn_final.caffemodel
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## putting test images  </span>
</span></span><span style=display:flex><span>cp data/VOCdevkit2007/VOC2007/JPEGImages/???.jpg data/demo/
</span></span><span style=display:flex><span><span style=color:#75715e>## ex</span>
</span></span><span style=display:flex><span><span style=color:#75715e>## cp data/VOCdevkit2007/VOC2007/JPEGImages/G25_000?00.jpg data/demo/</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## run demo  </span>
</span></span><span style=display:flex><span>./tools/demo_save_im.py --net zf  
</span></span></code></pre></div><p><img loading=lazy src=/images/2017-08-31/demo4.jpg>
<img loading=lazy src=/images/2017-08-31/demo5.jpg>
<img loading=lazy src=/images/2017-08-31/demo6.jpg></p><h2 id=troubleshooting>Troubleshooting<a hidden class=anchor aria-hidden=true href=#troubleshooting>#</a></h2><h3 id=ssh-no-display-issue>SSH: no display issue<a hidden class=anchor aria-hidden=true href=#ssh-no-display-issue>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ ./tool/demo.py
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Demo <span style=color:#66d9ef>for</span> data/demo/000456.jpg
</span></span><span style=display:flex><span>Detection took 0.198s <span style=color:#66d9ef>for</span> <span style=color:#ae81ff>300</span> object proposals
</span></span><span style=display:flex><span>Traceback <span style=color:#f92672>(</span>most recent call last<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;./tools/demo.py&#34;</span>, line 149, in &lt;module&gt;
</span></span><span style=display:flex><span>    demo<span style=color:#f92672>(</span>net, im_name<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;./tools/demo.py&#34;</span>, line 98, in demo
</span></span><span style=display:flex><span>    vis_detections<span style=color:#f92672>(</span>im, cls, dets, thresh<span style=color:#f92672>=</span>CONF_THRESH<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;./tools/demo.py&#34;</span>, line 47, in vis_detections
</span></span><span style=display:flex><span>    fig, ax <span style=color:#f92672>=</span> plt.subplots<span style=color:#f92672>(</span>figsize<span style=color:#f92672>=(</span>12, 12<span style=color:#f92672>))</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py&#34;</span>, line 1202, in subplots
</span></span><span style=display:flex><span>    fig <span style=color:#f92672>=</span> figure<span style=color:#f92672>(</span>**fig_kw<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py&#34;</span>, line 535, in figure
</span></span><span style=display:flex><span>    **kwargs<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_tkagg.py&#34;</span>, line 81, in new_figure_manager
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> new_figure_manager_given_figure<span style=color:#f92672>(</span>num, figure<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_tkagg.py&#34;</span>, line 89, in new_figure_manager_given_figure
</span></span><span style=display:flex><span>    window <span style=color:#f92672>=</span> Tk.Tk<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/usr/lib/python2.7/lib-tk/Tkinter.py&#34;</span>, line 1818, in __init__
</span></span><span style=display:flex><span>    self.tk <span style=color:#f92672>=</span> _tkinter.create<span style=color:#f92672>(</span>screenName, baseName, className, interactive, wantobjects, useTk, sync, use<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>_tkinter.TclError: no display name and no $DISPLAY environment variable
</span></span></code></pre></div><ol><li>Install Xming, Teamviewer or use X11 forwarding <code>ssh -X</code><br><a href=http://blog.csdn.net/j790675692/article/details/52693761>http://blog.csdn.net/j790675692/article/details/52693761</a></li><li>Modify ./tool/demo.py</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>diff --git a/tools/demo.py b/tools/demo.py
</span></span><span style=display:flex><span>index 631c68a..5016da5 100755
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/tools/demo.py
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/tools/demo.py
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -13,6 +13,9 @@ Demo script showing detections in sample images.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span> See README.md for installation instructions before running.
</span></span><span style=display:flex><span> &#34;&#34;&#34;
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span><span style=color:#a6e22e>+import matplotlib
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+matplotlib.use(&#39;Agg&#39;)
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span> import _init_paths
</span></span><span style=display:flex><span> from fast_rcnn.config import cfg
</span></span><span style=display:flex><span> from fast_rcnn.test import im_detect
</span></span><span style=display:flex><span><span style=color:#75715e>@@ -67,7 +72,9 @@ def vis_detections(im, class_name, dets, thresh=0.5):
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>                   fontsize=14)
</span></span><span style=display:flex><span>     plt.axis(&#39;off&#39;)
</span></span><span style=display:flex><span>     plt.tight_layout()
</span></span><span style=display:flex><span><span style=color:#f92672>-    plt.draw()
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    #plt.draw()
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    pic_name = class_name + &#39;_&#39; + im_name
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    plt.savefig(pic_name)
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span> 
</span></span><span style=display:flex><span> def demo(net, image_name):
</span></span><span style=display:flex><span>     &#34;&#34;&#34;Detect object classes in an image using pre-computed object proposals.&#34;&#34;&#34;
</span></span></code></pre></div><h3 id=attributeerror-module-object-has-no-attribute-text_format>AttributeError: &lsquo;module&rsquo; object has no attribute &rsquo;text_format&rsquo;<a hidden class=anchor aria-hidden=true href=#attributeerror-module-object-has-no-attribute-text_format>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ ./experiments/scripts/faster_rcnn_alt_opt.sh <span style=color:#ae81ff>0</span> VGG16 pascal_voc
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>libprotobuf WARNING google/protobuf/io/coded_stream.cc:78<span style=color:#f92672>]</span> The total number of bytes read was <span style=color:#ae81ff>553432430</span>
</span></span><span style=display:flex><span>I0804 08:22:22.416573  <span style=color:#ae81ff>2399</span> net.cpp:816<span style=color:#f92672>]</span> Ignoring source layer pool5
</span></span><span style=display:flex><span>I0804 08:22:22.539361  <span style=color:#ae81ff>2399</span> net.cpp:816<span style=color:#f92672>]</span> Ignoring source layer relu7
</span></span><span style=display:flex><span>I0804 08:22:22.539386  <span style=color:#ae81ff>2399</span> net.cpp:816<span style=color:#f92672>]</span> Ignoring source layer drop7
</span></span><span style=display:flex><span>I0804 08:22:22.539389  <span style=color:#ae81ff>2399</span> net.cpp:816<span style=color:#f92672>]</span> Ignoring source layer fc8
</span></span><span style=display:flex><span>I0804 08:22:22.539392  <span style=color:#ae81ff>2399</span> net.cpp:816<span style=color:#f92672>]</span> Ignoring source layer prob
</span></span><span style=display:flex><span>Process Process-1:
</span></span><span style=display:flex><span>Traceback <span style=color:#f92672>(</span>most recent call last<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/usr/lib/python2.7/multiprocessing/process.py&#34;</span>, line 258, in _bootstrap
</span></span><span style=display:flex><span>    self.run<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/usr/lib/python2.7/multiprocessing/process.py&#34;</span>, line 114, in run
</span></span><span style=display:flex><span>    self._target<span style=color:#f92672>(</span>*self._args, **self._kwargs<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;./tools/train_faster_rcnn_alt_opt.py&#34;</span>, line 129, in train_rpn
</span></span><span style=display:flex><span>    max_iters<span style=color:#f92672>=</span>max_iters<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/fast_rcnn/train.py&#34;</span>, line 157, in train_net
</span></span><span style=display:flex><span>    pretrained_model<span style=color:#f92672>=</span>pretrained_model<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/fast_rcnn/train.py&#34;</span>, line 51, in __init__
</span></span><span style=display:flex><span>    pb2.text_format.Merge<span style=color:#f92672>(</span>f.read<span style=color:#f92672>()</span>, self.solver_param<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>AttributeError: <span style=color:#e6db74>&#39;module&#39;</span> object has no attribute <span style=color:#e6db74>&#39;text_format&#39;</span>
</span></span></code></pre></div><p>install protobuf==2.6.0</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ sudo pip install protobuf<span style=color:#f92672>==</span>2.6.0
</span></span></code></pre></div><p>Ref: <a href=http://blog.csdn.net/qq_32768743/article/details/74639381>http://blog.csdn.net/qq_32768743/article/details/74639381</a></p><h3 id=out-of-memory>Out of Memory<a hidden class=anchor aria-hidden=true href=#out-of-memory>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>I0804 08:28:56.610743  <span style=color:#ae81ff>2742</span> net.cpp:270<span style=color:#f92672>]</span> This network produces output rpn_loss_bbox
</span></span><span style=display:flex><span>I0804 08:28:56.610782  <span style=color:#ae81ff>2742</span> net.cpp:283<span style=color:#f92672>]</span> Network initialization <span style=color:#66d9ef>done</span>.
</span></span><span style=display:flex><span>I0804 08:28:56.610920  <span style=color:#ae81ff>2742</span> solver.cpp:60<span style=color:#f92672>]</span> Solver scaffolding <span style=color:#66d9ef>done</span>.
</span></span><span style=display:flex><span>Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>libprotobuf WARNING google/protobuf/io/coded_stream.cc:537<span style=color:#f92672>]</span> Reading dangerously large protocol message.  If the message turns out to be larger than <span style=color:#ae81ff>2147483647</span> bytes, parsing will be halted <span style=color:#66d9ef>for</span> security reasons.  To increase the limit <span style=color:#f92672>(</span>or to disable these warnings<span style=color:#f92672>)</span>, see CodedInputStream::SetTotalBytesLimit<span style=color:#f92672>()</span> in google/protobuf/io/coded_stream.h.
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>libprotobuf WARNING google/protobuf/io/coded_stream.cc:78<span style=color:#f92672>]</span> The total number of bytes read was <span style=color:#ae81ff>553432430</span>
</span></span><span style=display:flex><span>I0804 08:28:56.840101  <span style=color:#ae81ff>2742</span> net.cpp:816<span style=color:#f92672>]</span> Ignoring source layer pool5
</span></span><span style=display:flex><span>I0804 08:28:56.961663  <span style=color:#ae81ff>2742</span> net.cpp:816<span style=color:#f92672>]</span> Ignoring source layer relu7
</span></span><span style=display:flex><span>I0804 08:28:56.961685  <span style=color:#ae81ff>2742</span> net.cpp:816<span style=color:#f92672>]</span> Ignoring source layer drop7
</span></span><span style=display:flex><span>I0804 08:28:56.961688  <span style=color:#ae81ff>2742</span> net.cpp:816<span style=color:#f92672>]</span> Ignoring source layer fc8
</span></span><span style=display:flex><span>I0804 08:28:56.961689  <span style=color:#ae81ff>2742</span> net.cpp:816<span style=color:#f92672>]</span> Ignoring source layer prob
</span></span><span style=display:flex><span>Solving...
</span></span><span style=display:flex><span>F0804 08:28:57.365995  <span style=color:#ae81ff>2742</span> syncedmem.cpp:56<span style=color:#f92672>]</span> Check failed: error <span style=color:#f92672>==</span> cudaSuccess <span style=color:#f92672>(</span><span style=color:#ae81ff>2</span> vs. 0<span style=color:#f92672>)</span>  out of memory
</span></span><span style=display:flex><span>*** Check failure stack trace: ***
</span></span><span style=display:flex><span>^C
</span></span><span style=display:flex><span>dlsummer@dlsummer-BM1AF-BP1AF-BM6AF:~/RCNN-install/py-faster-rcnn$ free -m
</span></span><span style=display:flex><span>              total        used        free      shared  buff/cache   available
</span></span><span style=display:flex><span>Mem:          <span style=color:#ae81ff>11887</span>         <span style=color:#ae81ff>237</span>       <span style=color:#ae81ff>10480</span>          <span style=color:#ae81ff>17</span>        <span style=color:#ae81ff>1168</span>       <span style=color:#ae81ff>11350</span>
</span></span><span style=display:flex><span>Swap:         <span style=color:#ae81ff>12159</span>           <span style=color:#ae81ff>0</span>       <span style=color:#ae81ff>12159</span>
</span></span></code></pre></div><p><strong>The graphic car out of memory</strong>
Tried to train ZF model.
GTX1060 may not have enough memory for VGG16.
(I&rsquo;m not sure the GPU is 6G ver. or 3G ver.)</p><p>In ZF model, you should modify:</p><ol><li>stage1_rpn_train.pt line 11</li><li>stage1.fast_rcnn_train.pt line 14, line 247 (In layer &ldquo;cls_score&rdquo;), line 266 (In layer &ldquo;bbox_pred&rdquo;)</li><li>stage2_rpn_train.pt line 11</li><li>stage2.fast_rcnn_train.pt line 14, line 247 (In layer &ldquo;cls_score&rdquo;), line 266 (In layer &ldquo;bbox_pred&rdquo;)</li><li>faster_rcnn_test.pt line 306 (In layer &ldquo;cls_score&rdquo;), line 315 (In layer &ldquo;bbox_pred&rdquo;)</li></ol><h3 id=typeerror-numpyfloat64-object-cannot-be-interpreted-as-an-index>TypeError: &rsquo;numpy.float64&rsquo; object cannot be interpreted as an index<a hidden class=anchor aria-hidden=true href=#typeerror-numpyfloat64-object-cannot-be-interpreted-as-an-index>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Process Process-3:
</span></span><span style=display:flex><span>Traceback <span style=color:#f92672>(</span>most recent call last<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/usr/lib/python2.7/multiprocessing/process.py&#34;</span>, line 258, in _bootstrap
</span></span><span style=display:flex><span>    self.run<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/usr/lib/python2.7/multiprocessing/process.py&#34;</span>, line 114, in run
</span></span><span style=display:flex><span>    self._target<span style=color:#f92672>(</span>*self._args, **self._kwargs<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;./tools/train_faster_rcnn_alt_opt.py&#34;</span>, line 196, in train_fast_rcnn
</span></span><span style=display:flex><span>    max_iters<span style=color:#f92672>=</span>max_iters<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/fast_rcnn/train.py&#34;</span>, line 160, in train_net
</span></span><span style=display:flex><span>    model_paths <span style=color:#f92672>=</span> sw.train_model<span style=color:#f92672>(</span>max_iters<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/fast_rcnn/train.py&#34;</span>, line 101, in train_model
</span></span><span style=display:flex><span>    self.solver.step<span style=color:#f92672>(</span>1<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/layer.py&#34;</span>, line 144, in forward
</span></span><span style=display:flex><span>    blobs <span style=color:#f92672>=</span> self._get_next_minibatch<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/layer.py&#34;</span>, line 63, in _get_next_minibatch
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> get_minibatch<span style=color:#f92672>(</span>minibatch_db, self._num_classes<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/minibatch.py&#34;</span>, line 55, in get_minibatch
</span></span><span style=display:flex><span>    num_classes<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/minibatch.py&#34;</span>, line 100, in _sample_rois
</span></span><span style=display:flex><span>    fg_inds, size<span style=color:#f92672>=</span>fg_rois_per_this_image, replace<span style=color:#f92672>=</span>False<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;mtrand.pyx&#34;</span>, line 1187, in mtrand.RandomState.choice <span style=color:#f92672>(</span>numpy/random/mtrand/mtrand.c:18864<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>TypeError: <span style=color:#e6db74>&#39;numpy.float64&#39;</span> object cannot be interpreted as an index
</span></span></code></pre></div><p><strong>Solution:</strong><br><a href=https://github.com/rbgirshick/py-faster-rcnn/issues/481>https://github.com/rbgirshick/py-faster-rcnn/issues/481</a></p><blockquote><blockquote><p>There seems to be a similar error caused by line 173 in lib/roi_data_layer/minibatch.py.<br>cls = clss[ind]<br>This is then used to slice bbox_targets[], however it is not an int and throws an error after hours of training. Change it to,<br>cls = int(clss[ind])<br>You will save yourself a headache.</p></blockquote></blockquote><p>vi lib/roi_data_layer/minibatch.py<br>line 173: cls = int(clss[ind])</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>diff --git a/lib/roi_data_layer/minibatch.py b/lib/roi_data_layer/minibatch.py
</span></span><span style=display:flex><span>index f4535b0..dc15c62 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/lib/roi_data_layer/minibatch.py
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/lib/roi_data_layer/minibatch.py
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -93,7 +93,7 @@ def _sample_rois(roidb, fg_rois_per_image, rois_per_image, num_classes):
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>     fg_inds = np.where(overlaps &gt;= cfg.TRAIN.FG_THRESH)[0]
</span></span><span style=display:flex><span>     # Guard against the case when an image has fewer than fg_rois_per_image
</span></span><span style=display:flex><span>     # foreground RoIs
</span></span><span style=display:flex><span><span style=color:#f92672>-    fg_rois_per_this_image = np.minimum(fg_rois_per_image, fg_inds.size)
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    fg_rois_per_this_image = int(np.minimum(fg_rois_per_image, fg_inds.size))
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>     # Sample foreground regions without replacement
</span></span><span style=display:flex><span>     if fg_inds.size &gt; 0:
</span></span><span style=display:flex><span>         fg_inds = npr.choice(
</span></span><span style=display:flex><span><span style=color:#75715e>@@ -105,8 +105,8 @@ def _sample_rois(roidb, fg_rois_per_image, rois_per_image, num_classes):
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>     # Compute number of background RoIs to take from this image (guarding
</span></span><span style=display:flex><span>     # against there being fewer than desired)
</span></span><span style=display:flex><span>     bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image
</span></span><span style=display:flex><span><span style=color:#f92672>-    bg_rois_per_this_image = np.minimum(bg_rois_per_this_image,
</span></span></span><span style=display:flex><span><span style=color:#f92672>-                                        bg_inds.size)
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    bg_rois_per_this_image = int(np.minimum(bg_rois_per_this_image,
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+                                        bg_inds.size))
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>     # Sample foreground regions without replacement
</span></span><span style=display:flex><span>     if bg_inds.size &gt; 0:
</span></span><span style=display:flex><span>         bg_inds = npr.choice(
</span></span><span style=display:flex><span><span style=color:#75715e>@@ -170,7 +170,7 @@ def _get_bbox_regression_labels(bbox_target_data, num_classes):
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>     bbox_inside_weights = np.zeros(bbox_targets.shape, dtype=np.float32)
</span></span><span style=display:flex><span>     inds = np.where(clss &gt; 0)[0]
</span></span><span style=display:flex><span>     for ind in inds:
</span></span><span style=display:flex><span><span style=color:#f92672>-        cls = clss[ind]
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+        cls = int(clss[ind])
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>         start = 4 * cls
</span></span><span style=display:flex><span>         end = start + 4
</span></span><span style=display:flex><span>         bbox_targets[ind, start:end] = bbox_target_data[ind, 1:]
</span></span></code></pre></div><h3 id=importerror-numpycoremultiarray-failed-to-import>ImportError: numpy.core.multiarray failed to import<a hidden class=anchor aria-hidden=true href=#importerror-numpycoremultiarray-failed-to-import>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Traceback <span style=color:#f92672>(</span>most recent call last<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;./tools/train_faster_rcnn_alt_opt.py&#34;</span>, line 19, in &lt;module&gt;
</span></span><span style=display:flex><span>    from datasets.factory import get_imdb
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/datasets/factory.py&#34;</span>, line 13, in &lt;module&gt;
</span></span><span style=display:flex><span>    from datasets.coco import coco
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/datasets/coco.py&#34;</span>, line 20, in &lt;module&gt;
</span></span><span style=display:flex><span>    from pycocotools.coco import COCO
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/pycocotools/coco.py&#34;</span>, line 58, in &lt;module&gt;
</span></span><span style=display:flex><span>    import mask
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/pycocotools/mask.py&#34;</span>, line 3, in &lt;module&gt;
</span></span><span style=display:flex><span>    import pycocotools._mask as _mask
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;pycocotools/_mask.pyx&#34;</span>, line 20, in init pycocotools._mask
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;__init__.pxd&#34;</span>, line 989, in numpy.import_array
</span></span><span style=display:flex><span>ImportError: numpy.core.multiarray failed to import
</span></span></code></pre></div><p><strong>Solution:</strong></p><p><code>sudo -H pip install --upgrade numpy</code></p><h3 id=typeerror-only-length-1-arrays-can-be-converted-to-python-scalars>TypeError: only length-1 arrays can be converted to Python scalars<a hidden class=anchor aria-hidden=true href=#typeerror-only-length-1-arrays-can-be-converted-to-python-scalars>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Process Process-3:
</span></span><span style=display:flex><span>Traceback <span style=color:#f92672>(</span>most recent call last<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/usr/lib/python2.7/multiprocessing/process.py&#34;</span>, line 258, in _bootstrap
</span></span><span style=display:flex><span>    self.run<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/usr/lib/python2.7/multiprocessing/process.py&#34;</span>, line 114, in run
</span></span><span style=display:flex><span>    self._target<span style=color:#f92672>(</span>*self._args, **self._kwargs<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;./tools/train_faster_rcnn_alt_opt.py&#34;</span>, line 196, in train_fast_rcnn
</span></span><span style=display:flex><span>    max_iters<span style=color:#f92672>=</span>max_iters<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/fast_rcnn/train.py&#34;</span>, line 160, in train_net
</span></span><span style=display:flex><span>    model_paths <span style=color:#f92672>=</span> sw.train_model<span style=color:#f92672>(</span>max_iters<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/fast_rcnn/train.py&#34;</span>, line 101, in train_model
</span></span><span style=display:flex><span>    self.solver.step<span style=color:#f92672>(</span>1<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/layer.py&#34;</span>, line 144, in forward
</span></span><span style=display:flex><span>    blobs <span style=color:#f92672>=</span> self._get_next_minibatch<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/layer.py&#34;</span>, line 63, in _get_next_minibatch
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> get_minibatch<span style=color:#f92672>(</span>minibatch_db, self._num_classes<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/minibatch.py&#34;</span>, line 55, in get_minibatch
</span></span><span style=display:flex><span>    num_classes<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  File <span style=color:#e6db74>&#34;/home/dlsummer/RCNN-install/py-faster-rcnn/tools/../lib/roi_data_layer/minibatch.py&#34;</span>, line 100, in _sample_rois
</span></span><span style=display:flex><span>    int<span style=color:#f92672>(</span>fg_inds<span style=color:#f92672>)</span>, size<span style=color:#f92672>=</span>fg_rois_per_this_image, replace<span style=color:#f92672>=</span>False<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>TypeError: only length-1 arrays can be converted to Python scalars
</span></span></code></pre></div><p><strong>Solution</strong><br>vi lib/roi_data_layer/minibatch.py<br>line 100: size=int(fg_rois_per_this_image)</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://oopsmonk.github.io/tags/linux/>Linux</a></li><li><a href=https://oopsmonk.github.io/tags/machinelearning/>MachineLearning</a></li></ul><nav class=paginav><a class=prev href=https://oopsmonk.github.io/posts/2017-08-29-2017month9/><span class=title>« Prev</span><br><span>Waterline?</span>
</a><a class=next href=https://oopsmonk.github.io/posts/2017-08-02-2017month8/><span class=title>Next »</span><br><span>Going Deep</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Faster R-CNN Use Caffe Framework on x" href="https://x.com/intent/tweet/?text=Faster%20R-CNN%20Use%20Caffe%20Framework&amp;url=https%3a%2f%2foopsmonk.github.io%2fposts%2f2017-08-31-faster-r-cnn-use-caffe-framework%2f&amp;hashtags=Linux%2cMachineLearning"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Faster R-CNN Use Caffe Framework on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2foopsmonk.github.io%2fposts%2f2017-08-31-faster-r-cnn-use-caffe-framework%2f&amp;title=Faster%20R-CNN%20Use%20Caffe%20Framework&amp;summary=Faster%20R-CNN%20Use%20Caffe%20Framework&amp;source=https%3a%2f%2foopsmonk.github.io%2fposts%2f2017-08-31-faster-r-cnn-use-caffe-framework%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Faster R-CNN Use Caffe Framework on reddit" href="https://reddit.com/submit?url=https%3a%2f%2foopsmonk.github.io%2fposts%2f2017-08-31-faster-r-cnn-use-caffe-framework%2f&title=Faster%20R-CNN%20Use%20Caffe%20Framework"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Faster R-CNN Use Caffe Framework on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2foopsmonk.github.io%2fposts%2f2017-08-31-faster-r-cnn-use-caffe-framework%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Faster R-CNN Use Caffe Framework on whatsapp" href="https://api.whatsapp.com/send?text=Faster%20R-CNN%20Use%20Caffe%20Framework%20-%20https%3a%2f%2foopsmonk.github.io%2fposts%2f2017-08-31-faster-r-cnn-use-caffe-framework%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Faster R-CNN Use Caffe Framework on telegram" href="https://telegram.me/share/url?text=Faster%20R-CNN%20Use%20Caffe%20Framework&amp;url=https%3a%2f%2foopsmonk.github.io%2fposts%2f2017-08-31-faster-r-cnn-use-caffe-framework%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Faster R-CNN Use Caffe Framework on ycombinator" href="https://news.ycombinator.com/submitlink?t=Faster%20R-CNN%20Use%20Caffe%20Framework&u=https%3a%2f%2foopsmonk.github.io%2fposts%2f2017-08-31-faster-r-cnn-use-caffe-framework%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://oopsmonk.github.io/>oopsmonk</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js integrity="sha512-J3G1KdOKUuj92x5w2mV/7AmPckHbiTQdoPXd6qaeHemfcNOsuwFVQm851m+lLuJR33sGuz9TAzWtccXZOsFE0Q==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>const images=Array.from(document.querySelectorAll(".post-content img"));images.forEach(e=>{mediumZoom(e,{background:"#808B96",margin:30,scrollOffset:30,container:null,template:null})})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>